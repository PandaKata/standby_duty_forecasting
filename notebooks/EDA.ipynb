{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, I analyze the dataset underlying the ML model for scheduling standby drivers.\n",
    "<br>\n",
    "I want to clarify which variables are interrelated, how they are distributed and thus find out which ones are suitable for the model as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fragen?\n",
    "* Are the data seasonal?\n",
    "* What is the connection between how many standby drivers are needed?\n",
    "* Frage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kata/Desktop/GitHub/standby_duty_forecasting/sickness_table.csv') #, index_col=0)\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the data is already in chronological order and the time stamps are equidistant in time series. This is already the case in our data: The time interval is one day and the data is already in chronological order. Therefore, we do not have to do this additional data preparation step.\n",
    "<br>\n",
    "This column is provided in string format. Let's convert it to the datetime64[ns] data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quelle](https://www.kaggle.com/code/iamleonie/intro-to-time-series-forecasting/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().style.set_properties(subset=['date'], **{'background-color': 'dodgerblue'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **date:** entry date\n",
    "* **n_sick:** number of drivers called sick on duty\n",
    "* **calls:** number of emergency calls\n",
    "* **n_duty:** number of drivers on duty available\n",
    "* **n_sby:** number of standby resources available\n",
    "* **sby_need:** number of standbys, which are activated on a given day\n",
    "* **dafted:** number of additional drivers needed due to not enough standbys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check time intervals\n",
    "df = df.sort_values(by='date')\n",
    "df['Time_Interval'] = df.date - df.date.shift(1)\n",
    "\n",
    "df[['date', 'Time_Interval']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be in chronological order and the timestamps should be equidistant in time series. \n",
    "<br>\n",
    "&rarr; IT IS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at numerical summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least 4074 calls were received during the period, maximum 11.850. On average, 7919.53 calls were received.\n",
    "<br>\n",
    "On average, 34.7 drivers are needed on standby. However, since the maximum is 555, it is worth looking for outliers here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for NaN-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data types exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sehen die Were in verschiedenen Spalten aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n_duty.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, there is only three options of drivers on duty. The values increase over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n_sby.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are always 90 drivers on standby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(data):\n",
    "    print(data.min())\n",
    "    print(data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max(df.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data covers a period of three years, from April 1st 2016 to May 27th 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix between all the features we are examining and our y-variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate graphically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pairplots to investigate data further and spot correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_sick und calls sind saisonal, bei sby_need und calls sieht man, dass es erst ab 8000 calls Standby-Fahrer braucht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of \"sby_need\" looks interesting, this is how the histogram looks in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.clf()\n",
    "plt.hist(df.sby_need, bins=50)\n",
    "plt.title('Standby drivers needed', fontsize=14)\n",
    "plt.xlabel('Number of standby drivers needed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = df.groupby(['sby_need']).size()\n",
    "print(new_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standby drivers were not needed in nearly three-quarters of the cases. However, there are also individual cases in which several hundred were needed.\n",
    "<br>\n",
    "Another graphic will illustrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed???\n",
    "plt.clf()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(new_df2)\n",
    "plt.axis([0, 555, 0, 5])\n",
    "plt.title('Required standby drivers', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time no standby drivers were needed, otherwise between 2 and 5. It could become problematic that there are numerous individual cases where hundreds were needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data over the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.plot(df.date, df.sby_need)\n",
    "#plt.xticks([204, 650, 900], ['19.4.2016', '16.5.2016', '4.6.2016'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the number of drivers increases over the years. Is there a correlation with the number of calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.lineplot(x='date', y='calls', hue='n_duty', data=df, linewidth = 0.8)\n",
    "#plt.xticks([0, 275, 640, 1151], ['01.04.2016', '01.01.2017', '01.01.2018', '27.05.2019'])\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(labels=[\"1700\",\"1800\", \"1900\"], title = \"Drivers on Duty\")\n",
    "plt.xlabel('Date', fontsize=13)\n",
    "plt.ylabel('Calls', fontsize=13)\n",
    "plt.title('Development of drivers on duty and emergency calls', fontsize=18)\n",
    "\n",
    "plt.savefig(\"dev_n_duty_calls.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows that the number of drivers on duty increases with the number of calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(df.calls, df.n_duty)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Pearson's correlation coefficient r, the two variables are slightly positively correlated with a value of 0.36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the number of calls and the number of drivers on sick leave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.regplot(x='calls', y='n_sick', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.title('Development of sick drivers and emergency calls', fontsize=18)\n",
    "plt.xlabel('Calls', fontsize=13)\n",
    "plt.ylabel('Sick drivers', fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of calls increases, the number of sick drivers slightly increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(df.calls, df.n_sick)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are weakly positively correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pairplot above suggests a correlation between calls and drivers needed. Pearson's r confirms this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(df.calls, df.sby_need)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables \"n_sick\" and \"sby_need\" are less related than thought:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(df.n_sick, df.sby_need)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if data is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some time-series models, such as such as ARIMA, assume that the underlying data is stationary. Stationarity describes that the time-series has\n",
    "<br>\n",
    "* constant mean and mean is not time-dependent\n",
    "* constant variance and variance is not time-dependent\n",
    "* constant covariance and covariance is not time-dependent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a time series has a specific (stationary) behavior over a given time interval, then it can be assumed that the time series will behave the same at a later time.\n",
    "<br>\n",
    "Time series with trend and/or seasonality are not stationary. Trend indicates that the mean is not constant over time and seasonality indicates that the variance is not constant over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.kaggle.com/code/iamleonie/intro-to-time-series-forecasting/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sby_need\n",
    "rolling_window = 52\n",
    "sns.lineplot(x=df.date, y=df.sby_need, color='indianred')\n",
    "sns.lineplot(x=df.date, y=df.sby_need.rolling(rolling_window).mean(), color='black', label='rolling mean')\n",
    "sns.lineplot(x=df.date, y=df.sby_need.rolling(rolling_window).std(), color='blue', label='rolling std')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and variance is not constant.\n",
    "<br>\n",
    "&rarr; doesn't seem to be stationary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls\n",
    "sns.lineplot(x=df.date, y=df.calls, color='indianred')\n",
    "sns.lineplot(x=df.date, y=df.calls.rolling(rolling_window).mean(), color='black', label='rolling mean')\n",
    "sns.lineplot(x=df.date, y=df.calls.rolling(rolling_window).std(), color='blue', label='rolling std')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and variance is not constant.\n",
    "<br>\n",
    "&rarr; doesn't seem to be stationary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var(data):\n",
    "    X = data.values\n",
    "    split = round(len(X) / 2)\n",
    "    X1, X2 = X[0:split], X[split:]\n",
    "    mean1, mean2 = X1.mean(), X2.mean()\n",
    "    var1, var2 = X1.var(), X2.var()\n",
    "    print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
    "    print('variance1=%f, variance2=%f' % (var1, var2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for standby drivers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_var(df.sby_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_var(df.calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and variance values for both are different and not in the same ball park."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented Dickey-Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sby_need\n",
    "result = adfuller(df.sby_need.values)\n",
    "adf_stat = result[0]\n",
    "p_val = result[1]\n",
    "crit_val_1 = result[4]['1%']\n",
    "crit_val_5 = result[4]['5%']\n",
    "crit_val_10 = result[4]['10%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_adfuller_results(series, title, ax):\n",
    "    result = adfuller(series)\n",
    "    significance_level = 0.05\n",
    "    adf_stat = result[0]\n",
    "    p_val = result[1]\n",
    "    crit_val_1 = result[4]['1%']\n",
    "    crit_val_5 = result[4]['5%']\n",
    "    crit_val_10 = result[4]['10%']\n",
    "\n",
    "    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n",
    "        linecolor = 'forestgreen' \n",
    "    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n",
    "        linecolor = 'gold'\n",
    "    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n",
    "        linecolor = 'orange'\n",
    "    else:\n",
    "        linecolor = 'indianred'\n",
    "    sns.lineplot(x=df.date, y=series, ax=ax, color=linecolor)\n",
    "    ax.set_title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n",
    "    ax.set_ylabel(ylabel=title, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 7))\n",
    "visualize_adfuller_results(df.sby_need.values, 'sby_need', ax[0])\n",
    "visualize_adfuller_results(df.calls.values, 'calls', ax[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sby_need:\n",
    "<br>\n",
    "**p-value <= significance level (0.05)**: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "<br>\n",
    "(**ADF statistic < critical value**: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calls:\n",
    "<br>\n",
    "**p-value > significance level**: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary. \n",
    "<br>\n",
    "(**ADF statistic < critical value**: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&rarr; calls not stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the test prints the test statistic value of -6. The more negative this statistic, the more likely we are to reject the null hypothesis (we have a stationary dataset).\n",
    "<br>\n",
    "As part of the output, we get a look-up table to help determine the ADF statistic. We can see that our statistic value of -6 is less than the value of -3.436 at 1%.\n",
    "<br>\n",
    "This suggests that we can reject the null hypothesis with a significance level of less than 1% (i.e. a low probability that the result is a statistical fluke).\n",
    "<br>\n",
    "We can also look at the p-value, which is 0. This means we can easily reject the null and consider the distribution as stationary.\n",
    "<br>\n",
    "Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure.\n",
    "<br>\n",
    "<br>\n",
    "&rarr; the data is  stationary ([Tutorial](https://machinelearningmastery.com/time-series-data-stationary-python/)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPSS test for stationarity\n",
    "\n",
    "<br>\n",
    "KPSS test is a statistical test to check for stationarity of a series around a deterministic trend. Like ADF test, the KPSS test is also commonly used to analyse the stationarity of a series. However, it has couple of key differences compared to the ADF test in function and in practical usage. Therefore, is not safe to just use them interchangeably. We’ll discuss this detail with simplified examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Resource](https://www.machinelearningplus.com/time-series/kpss-test-for-stationarity/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference from ADF test is the null hypothesis of the KPSS test is that the series is stationary.\n",
    "<br>\n",
    "So practically, the interpretaion of p-value is just the opposite to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eher den nehmen!!!!!!!!!\n",
    "\n",
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)\n",
    "\n",
    "\n",
    "print('CALLS')\n",
    "kpss_test(df.calls)\n",
    "print('SBY NEED')\n",
    "kpss_test(df.sby_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is evidence for rejecting the null hypothesis in favor of the alternative. Hence, both series are non-stationary as per the KPSS test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with or without regression?\n",
    "# zweite quelle: https://www.machinelearningplus.com/time-series/kpss-test-for-stationarity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpss_test2(series, **kw):    \n",
    "    statistic, p_value, n_lags, critical_values = kpss(series, **kw)\n",
    "    # Format Output\n",
    "    print(f'KPSS Statistic: {statistic}')\n",
    "    print(f'p-value: {p_value}')\n",
    "    print(f'num lags: {n_lags}')\n",
    "    print('Critial Values:')\n",
    "    for key, value in critical_values.items():\n",
    "        print(f'   {key} : {value}')\n",
    "    print(f'Result: The series is {\"not \" if p_value < 0.05 else \"\"}stationary')\n",
    "\n",
    "print('CALLS')\n",
    "kpss_test2(df.calls, regression=\"c\")\n",
    "print('SBY NEED')\n",
    "kpss_test2(df.sby_need, regression=\"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL RESULT: Calls non stationary\n",
    "<br>\n",
    "KPSS indicates non-stationarity and ADF indicates stationarity - The series is difference stationary. Differencing is to be used to make series stationary. The differenced series is checked for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Difference between KPSS and ADF](https://www.machinelearningplus.com/time-series/kpss-test-for-stationarity/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stationary calls???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make calls stationary???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation of non stationary calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transform of absolute values\n",
    "# (Log transoform of negative values will return NaN)\n",
    "df['calls_log'] = np.log(abs(df.calls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 6))\n",
    "visualize_adfuller_results(abs(df.calls), 'Absolute \\n Calls', ax[0, 0])\n",
    "\n",
    "sns.distplot(df.calls_log, ax=ax[0, 1])\n",
    "visualize_adfuller_results(df.calls_log, 'Transformed \\n Calls', ax[1, 0])\n",
    "\n",
    "sns.distplot(df.calls_log, ax=ax[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hä?? was hat das gebracht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way: differencing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Order Differencing\n",
    "calls_diff = np.diff(df.calls)\n",
    "df['calls_diff_1'] = np.append([0], calls_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The differencing can be reverted if the the first value before differencing is known. \n",
    "# In this case, we can accumulate all values with the function .cumsum() and add the first value of the original time series.\n",
    "\n",
    "\n",
    "df.calls.equals(df.calls_diff_1.cumsum() + df.calls.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('p-value: ' + str(adfuller(df.calls_diff_1.dropna())[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA fängt eig erst hier an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check seasonality of the Standby drivers needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot(x='date', y='sby_need', figsize=(12,6))\n",
    "#plt.xticks([275, 640, 1005], ['01.01.2017', '01.01.2018', '01.01.2019'])\n",
    "xcoords = [275, 640, 1005]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='black', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seasonality of calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.plot(x='date', y='calls', figsize=(12,6))\n",
    "#plt.xticks([275, 640, 1005], ['01.01.2017', '01.01.2018', '01.01.2019'])\n",
    "xcoords = [275, 640, 1005]\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc, color='black', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seasonal decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split variable into components to see seasonal variation\n",
    "\n",
    "def decompose(data):\n",
    "    res = sm.tsa.seasonal_decompose(data, period=365, model='additive')\n",
    "    fig = res.plot()\n",
    "    fig.set_size_inches(14,7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose calls\n",
    "decompose(df.calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose(df.sby_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this [resource](https://www.alpharithms.com/autocorrelation-time-series-python-432909/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform autocorrelation & visualization\n",
    "def autocorr(data):\n",
    "    res = sm.graphics.tsa.plot_acf(x=data, lags=100)\n",
    "    res.set_size_inches(14,7)\n",
    "    plt.show()\n",
    "\n",
    "#The red shaded region is the confidence interval with a default value of α = 0.05. \n",
    "#Anything within this range represents a value that has no significant correlation with the most recent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr(df.sby_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr(df.calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lags over confidence intervall\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def get_lags(data):\n",
    "    a, ci = acf(x=data, nlags=100, alpha=0.05, fft=True)\n",
    "    centered_ci = ci - a[:,None]\n",
    "    outside = np.abs(a) >= centered_ci[:,1]\n",
    "    inside = ~outside\n",
    "\n",
    "    return outside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_sby = get_lags(df.sby_need)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_calls = get_lags(df.calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lags_count(array):\n",
    "    a = sum(x==True for x in array)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_count(lags_sby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_count(lags_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way\n",
    "# resource: https://www.kaggle.com/code/iamleonie/intro-to-time-series-forecasting/notebook\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "autocorrelation_plot(df.calls_diff_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(16, 8))\n",
    "\n",
    "plot_acf(df.calls_diff_1,lags=100, ax=ax[0])\n",
    "plot_pacf(df.calls_diff_1,lags=100, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation (WAS IS DAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 3\n",
    "\n",
    "X = df.date\n",
    "y = df.calls\n",
    "\n",
    "folds = TimeSeriesSplit(n_splits=N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=N_SPLITS, ncols=2, figsize=(16, 9))\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "    sns.lineplot(x= X_train, y= y_train, ax=ax[i,0], color='dodgerblue', label='train')\n",
    "    sns.lineplot(x= X_train[len(X_train) - len(X_valid):(len(X_train) - len(X_valid) + len(X_valid))], \n",
    "                 y= y_train[len(X_train) - len(X_valid):(len(X_train) - len(X_valid) + len(X_valid))], \n",
    "                 ax=ax[i,1], color='dodgerblue', label='train')\n",
    "\n",
    "    for j in range(2):\n",
    "        sns.lineplot(x= X_valid, y= y_valid, ax=ax[i, j], color='darkorange', label='validation')\n",
    "    ax[i, 0].set_title(f\"Rolling Window with Adjusting Training Size (Split {i+1})\", fontsize=16)\n",
    "    ax[i, 1].set_title(f\"Rolling Window with Constant Training Size (Split {i+1})\", fontsize=16)\n",
    "\n",
    "for i in range(N_SPLITS):\n",
    "    ax[i, 0].set_xlim([date(2016, 1, 1), date(2019, 6, 30)])\n",
    "    ax[i, 1].set_xlim([date(2016, 1, 1), date(2019, 6, 30)])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c3cd99063abd1b4c15ea40868a5df46d871e2273225f116d3d00cd8553a7cf8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
